{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e46001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from spikingjelly.activation_based.neuron import BaseNode\n",
    "\n",
    "import torch, wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.model import L2Net\n",
    "from utils.load import load_l2net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "writer = SummaryWriter(log_dir=\"./runs/l2_distance_experiment\")\n",
    "\n",
    "np.random.seed(42)\n",
    "rng = torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818b2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=10_000, precision=2, linewidth=160, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15e0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(\n",
    "    NUM_SAMPLES = 100000,\n",
    "    NUM_EPOCHS = 100,\n",
    "    VECTOR_DIM = 64,\n",
    "    MIN_VAL = -6.,\n",
    "    MAX_VAL = 6.,\n",
    "    TIME_STEPS = 21,\n",
    "    JEFFRESS_COMPRESSION = 1,\n",
    "    BATCH_SIZE = 512,\n",
    "    INITIAL_ALPHA = 2,\n",
    "    MAX_ALPHA = 10.0,\n",
    "    LR = 3e-3,\n",
    "    EVAL_MODE = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9306340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = int(cfg[\"NUM_SAMPLES\"])  # 총 1000 개의 샘플 생성\n",
    "NUM_EPOCHS = int(cfg[\"NUM_EPOCHS\"])\n",
    "VECTOR_DIM = int(cfg[\"VECTOR_DIM\"])      # 각 벡터는 3차원\n",
    "MIN_VAL = cfg[\"MIN_VAL\"]\n",
    "MAX_VAL = cfg[\"MAX_VAL\"]\n",
    "TIME_STEPS = int(cfg[\"TIME_STEPS\"])  # 각 레이어 당 17 타임스텝\n",
    "JEFFRESS_COMPRESSION = int(cfg[\"JEFFRESS_COMPRESSION\"])\n",
    "BATCH_SIZE = int(cfg[\"BATCH_SIZE\"])\n",
    "INITIAL_ALPHA = float(cfg[\"INITIAL_ALPHA\"])\n",
    "MAX_ALPHA = float(cfg[\"MAX_ALPHA\"])\n",
    "LR = float(cfg[\"LR\"])\n",
    "EVAL_MODE = bool(cfg[\"EVAL_MODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0963381",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L2Net(TIME_STEPS,\n",
    "              VECTOR_DIM,\n",
    "              jeffress_radius=TIME_STEPS-1,\n",
    "              jeffress_compression=JEFFRESS_COMPRESSION,\n",
    "              temporal_min=MIN_VAL,\n",
    "              temporal_max=MAX_VAL,\n",
    "              accelerated=True,).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783028a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.datasets import generate_l2_square_dataset, encode_temporal_np\n",
    "\n",
    "X_data, y_data = generate_l2_square_dataset(NUM_SAMPLES, VECTOR_DIM, low=MIN_VAL, high=MAX_VAL, normalize=True)  # X_data: N 2 D, y_data: N\n",
    "X_data_temporal = torch.stack([torch.FloatTensor(encode_temporal_np(X_data[:,0,:], TIME_STEPS, 0, min_val=MIN_VAL, max_val=MAX_VAL)),\n",
    "                      torch.FloatTensor(encode_temporal_np(X_data[:,1,:], TIME_STEPS, 0, min_val=MIN_VAL, max_val=MAX_VAL))],\n",
    "                     dim=2) # T N 2D\n",
    "y_data = torch.FloatTensor(y_data) # N D\n",
    "dataset = torch.utils.data.TensorDataset(X_data_temporal.transpose(1, 0), y_data, torch.tensor(X_data))  # T N 2D -> N T 2D\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "current_alpha = INITIAL_ALPHA\n",
    "loss = torch.tensor(float(\"inf\"))\n",
    "\n",
    "pbar = tqdm(range(NUM_EPOCHS))\n",
    "pred_hist, target_hist, err_hist = [], [], []\n",
    "train_step = 0\n",
    "eval_step = 0\n",
    "substep = 0\n",
    "eval_substep = 0\n",
    "if not EVAL_MODE:\n",
    "    with wandb.init(project=\"DelayedTemporal\",\n",
    "                    config=cfg) as run:\n",
    "        run.define_metric(\"train/*\", step_metric=\"train_step\")\n",
    "        run.define_metric(\"delay/*\", step_metric=\"train_step\")\n",
    "        run.define_metric(\"SDC/*\", step_metric=\"train_step\")\n",
    "        run.define_metric(\"Neuron/*\", step_metric=\"substep\")\n",
    "        run.define_metric(\"eval/*\", step_metric=\"eval_step\")\n",
    "        run.define_metric(\"eval_sub/*\", step_metric=\"eval_substep\")\n",
    "        for epoch in pbar:\n",
    "            model.train()\n",
    "            \n",
    "            current_alpha = INITIAL_ALPHA + (MAX_ALPHA - INITIAL_ALPHA) * epoch / NUM_EPOCHS\n",
    "            for m in model.modules():\n",
    "                if isinstance(m, BaseNode):\n",
    "                    if hasattr(m.surrogate_function, \"alpha\"):\n",
    "                        setattr(m.surrogate_function, \"alpha\", min(current_alpha, 10.0))\n",
    "                        \n",
    "            for i, batch in enumerate(tqdm(train_loader, leave=False)):\n",
    "                inputs:Float[Tensor, \"N T 2 D\"]; targets:Float[Tensor, \"N D\"]\n",
    "                inputs, targets, input_raw = batch\n",
    "                inputs = inputs.to(device); targets = targets.to(device); input_raw = input_raw.to(device)\n",
    "                out = model(inputs.transpose(1, 0)) # N T 2 D -> T N 2 D -> model -> T N 1\n",
    "                pred = out\n",
    "                loss = criterion(pred, targets)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                pbar.set_postfix({\"loss\": loss.item(), \"scale\":(out.max()-out.min()).item(), \"lr\": scheduler.get_last_lr()[0]})\n",
    "                if i % 10 == 0:\n",
    "                    run.log({\n",
    "                        \"train_step\": (train_step := train_step + 1),\n",
    "                        \"train/loss\": loss.item(),\n",
    "                        \"train/err\":(pred - targets).abs().mean().item(),\n",
    "                        \"train/alpha\": current_alpha,\n",
    "                    # }|{\n",
    "                    #         f\"SDC/rate_{i}\": torch.stack(model.stats['jeffress_model.2.neuron'], dim=0).mean(dim=(0,1,2))[i] for i in range(2*TIME_STEPS - 1)\n",
    "                            }\n",
    "                    )\n",
    "                    # for t in range(2*TIME_STEPS):\n",
    "                    #     run.log({\n",
    "                    #         \"substep\": (substep := substep + 1),\n",
    "                    #     }\n",
    "                    #             |{\n",
    "                    #         f\"Neuron/I_{j}\": model.jeffress_model[2].i_seq[t][0,0,j] for j in range(2*TIME_STEPS - 1)\n",
    "                    #         }\n",
    "                    #             |{\n",
    "                    #         f\"Neuron/V_{j}\": model.jeffress_model[2].v_seq[t][0,0,j] for j in range(2*TIME_STEPS - 1)\n",
    "                    #         })\n",
    "            scheduler.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                for batch in tqdm(test_loader, leave=False):\n",
    "                    inputs, targets, input_raw = batch\n",
    "                    inputs = inputs.to(device); targets = targets.to(device); input_raw = input_raw.to(device)\n",
    "                    out = model(inputs.transpose(1, 0)) # NT(2D)->TN(2D)->model->N\n",
    "                    pred = out\n",
    "                    loss = criterion(pred, targets)\n",
    "                    pred_hist.extend(pred.squeeze().tolist())\n",
    "                    target_hist.extend(targets.squeeze().tolist())\n",
    "                    err_hist.extend(torch.abs(pred.squeeze() - targets.squeeze()).tolist())\n",
    "                    pbar.set_postfix({\"loss\": loss.item(), \"pred\": pred_hist[-1], \"target\": target_hist[-1]})\n",
    "                    \n",
    "                    run.log({\"eval_step\": (eval_step := eval_step + 1),\n",
    "                            \"eval/loss\": loss.item()})\n",
    "                    for n in range(pred.shape[0]):\n",
    "                        run.log({\"eval_substep\": (eval_substep := eval_substep + 1),\n",
    "                            \"eval_sub/err\":  (pred - targets).abs()[n].item()})\n",
    "else:\n",
    "    hex = \"fa73b386e47111f0a1fe0242ac11000f\"\n",
    "    models, cfg = load_l2net_model(hex, parallel=False)\n",
    "    model = models[torch.device(0)].to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            inputs, targets, input_raw = batch\n",
    "            inputs = inputs.to(device); targets = targets.to(device); input_raw = input_raw.to(device)\n",
    "            out = model(inputs.transpose(1, 0)) # NT(2D)->TN(2D)->model->N\n",
    "            pred = out\n",
    "            loss = criterion(pred, targets)\n",
    "            pred_hist.extend(pred.squeeze().tolist())\n",
    "            target_hist.extend(targets.squeeze().tolist())\n",
    "            err_hist.extend(torch.abs(pred.squeeze() - targets.squeeze()).tolist())\n",
    "    print(f\"Test MSE Loss: {loss.item():.6f}, MAE: {np.mean(err_hist):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not EVAL_MODE:\n",
    "    from uuid import uuid1\n",
    "    from json import load, dump\n",
    "    from pathlib import Path\n",
    "\n",
    "    save_id = uuid1().hex\n",
    "    save_dir = Path(f\"models/{save_id}\")\n",
    "\n",
    "    if not save_dir.exists():\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(\"models/contents.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        contents = load(f)\n",
    "\n",
    "    contents |= ({save_id: {\n",
    "        \"model\": model.__class__.__name__,\n",
    "        \"final_loss\": loss.item(),\n",
    "        \"final_mae\": np.mean(err_hist)} | cfg})\n",
    "\n",
    "    with open(\"models/contents.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        dump(contents, f, indent=4)\n",
    "\n",
    "    torch.save(model.state_dict(), save_dir / \"model.pt\")\n",
    "    torch.save(cfg, save_dir / \"model.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c56575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"MAE (Mean Absolute Error)\")\n",
    "plt.plot(err_hist, linewidth=0.025, label=\"Difference\")\n",
    "plt.ylim(-.1, 1)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110ba338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(err_hist[100000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8b711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
